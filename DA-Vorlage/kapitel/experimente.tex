\chapter{Experimente und Ergebnisse}
In diesem Kapitel werden verschiedene Experimente mit dem FPGA durchgeführt. Zunächst wird gemessen, Wie viel Zeit pro trainiertem Perzeptron für das Training und die Voraussagen auf dem FPGA und einer Implementierung auf dem Hostsystem aufgewendet werden muss. Hierbei wird das Programm auf dem Hostsystem nicht parallelisiert. 
Dann werden beispielhaft Trainingsvorgänge mit verschiedenen Datensätzen durchgeführt, um die Genauigkeit der Vorhersagen zu überprüfen und Ergebnisse der Testvorgänge zu präsentieren.\\
Es wird für die Experimente der Datensatz MNIST \cite{MNIST} verwendet.\\
Die Features $\vec f$ des Datensatzes wurden normalisiert, sodass $\forall f \in \vec f\text{ . } f \in [0,1]$. 
\section{Regularisierung}
Mit dem MNIST Datensatz wurden verschiedene Testzyklen zur Regularisierung durchgeführt. Für die Ergebnisse ist der Datentyp, soweit nicht anders vermerkt, auf eine Fixkommazahl mit einem Vorzeichen-, 4 Vorkommastellen- und 11 Nachkommastellenbits eingestellt. Ein Trainingsdurchlauf mit 200 Variablen und 100 Wiederholungen führte zu folgenden Ergebnissen: \\\\
\begin{tabularx}{\textwidth}{p{0.16\textwidth}|r|r|r|r|r}
Perceptron & Regularisierungsrate & Lernrate & Batch & Methode & Genauigkeit\\
\hline
a & 0.0 & 0.100098 & 1 & keine & 95.43\%\\
\hline
b & 0.007812 & 0.100098 & 1 & L2 & 95.75\%\\
\hline
c & 0.009766 & 0.100098 & 1 & L2 & 95.75\%\\
\hline
d & 0.5 & 0.100098 & 1 & L2 & 89.9\%\\
\hline
e & 0 & 0.100098 & 1 & L1 & 95.43\%\\
\hline
f & 0.000977 & 0.100098 & 1 & L1 & 95.43\%\\
\hline
g & 0.004883 & 0.100098 & 1 & L1 & 94.38\%\\
\hline
h & 0.009766 & 0.100098 & 1 & L1 & 93.38\%\\
\end{tabularx}\\\\
Hierbei wurde der Datensatz so angepasst, dass alle Variablen die die Ziffer "`3"' darstellen mit "`trifft zu"' und alle anderen Variablen mit "`trifft nicht zu"' markiert wurden.\\
Nach dem Auswerten der Koeffizienten sind die Einflüsse der Regularisierungsmethoden auf das gelernte Modell deutlich sichtbar. Die Ridge Regression erzielte bei diesem Versuch die besten Ergebnisse, was aufgrund der Daten nicht besonders überraschend war. Da MNIST aus 28x28 Pixeln in Schwarz-Weiß Werten besteht und diese eine handgeschriebene Ziffer repräsentieren war anzunehmen dass es nur wenige Features gibt  welche für das Ergebnis irrelevante Ausprägungen bieten. Demnach ist die LASSO Methode für diesen Datensatz nicht gut geeignet. Die Ridge Regression kann, mit ausreichend kleinem $C$, die Koeffizienten, die zu starke Auswirkungen auf das Modell haben reduzieren, sodass einem Overfitting entgegengewirkt wird. Allerdings hat der gewonnene Genauigkeitswert nur geringfügig zugenommen.\\
Zeichnet man die Koeffizienten als Graphen auf kann man die Auswirkung der Regularisierung auf die Regression deutlich erkennen. In den nachfolgenden Abbildungen 5.1, 5.2 und 5.3 werden diese Graphen dargestellt. Die Koeffizienten sind hierbei die Ergebnisse der obigen Trainingsdurchlaufs.
\begin{figure}[ht]
\centering
  	\includegraphics[scale=0.5]{bilder/features7}
  	\caption{L1 Regularisierung}
\end{figure}
\begin{figure}[ht]
\centering
  	\includegraphics[scale=0.5]{bilder/features2}
	\caption{L2 Regularisierung}
\end{figure}
\begin{figure}[ht]
\centering
\includegraphics[scale=.5]{bilder/features0}
\caption{Logistische Regression ohne Regularisierung}
\end{figure}\newpage
Bei der Verarbeitung von Bilddaten gibt es den großen Vorteil, dass sich die Koeffizienten selbst als Bild interpretieren lassen. In der ersten Zeile der folgenden Grafiken (Abbildung 5.4, 5.5, 5.6) wurden die Koeffizienten unverändert interpretiert, sodass negative Werte keinen Farbunterschied hervorrufen. Es sind auf den Bildern nur die Koeffizienten zu sehen die einen positiven Einfluss auf die Ausgabe haben, da sie die Features repräsentieren die das Vorhandensein einer Linie belohnen. Der Verlauf ist von Schwarz (keine oder negative Auswirkung) bis hin zu Weiß (positive Auswirkung).\\
In der zweiten Zeile (Abbildung 5.7, 5.8, 5.9) sind die Koeffizienten normalisiert worden, sodass die kleinste Ausprägung 0 und die größte Ausprägung 1 darstellen. Es wird also auch der negative Einfluss der Features berücksichtigt, also derer, die das Vorhandensein einer Linie bestrafen.\newpage
\begin{figure}[ht]
\centering
	\begin{minipage}[b]{.25\linewidth}
  		\includegraphics[scale=0.7]{bilder/l0_3}
  		\caption{ohne Regularisierung}
  	\end{minipage}
  	\hspace{.05\linewidth}% Abstand zwischen Bilder
  	\begin{minipage}[b]{.25\linewidth}
  		\includegraphics[scale=0.7]{bilder/l1_3}
		\caption{L1 \\Regularisierung}
	\end{minipage}
	\hspace{.05\linewidth}% Abstand zwischen Bilder
	\begin{minipage}[b]{.25\linewidth}
  		\includegraphics[scale=0.7]{bilder/l2_3}
  		\caption{L2 \\ Regularisierung}
  	\end{minipage}
	\begin{minipage}[b]{.25\linewidth}
  		\includegraphics[scale=0.7]{bilder/l0_3_g}
  		\caption{ohne Reg. normiert}
  	\end{minipage}
  	\hspace{.05\linewidth}% Abstand zwischen Bilder
  	\begin{minipage}[b]{.25\linewidth}
  		\includegraphics[scale=0.7]{bilder/l1_3_g}
		\caption{L1 normiert}
	\end{minipage}
	\hspace{.05\linewidth}% Abstand zwischen Bilder
	\begin{minipage}[b]{.25\linewidth}
  		\includegraphics[scale=0.7]{bilder/l2_3_g}
  		\caption{L2 normiert}
  	\end{minipage}
\end{figure}
Die MNIST Daten sind so auf den angezeigten Bildausschnitt normiert, das der Schwerpunkt der Pixel mit einer gezeichneten Linie zur Bildmitte hin verschoben ist. Die "`3"' zu Beispiel, wie in den Graphiken oben zu sehen, ist nach oben links im Bild verzogen, die "`9"' hingegen nach unten links.
Da sich nicht alle Ziffern perfekt überlappen gibt es für die L1 Regularisierung sehr wenige Koeffizienten, die auf 0 gesetzt werden können. Demnach hat diese Regularisierungsmethode nur mit kleiner Gewichtung eine positive Auswirkung auf das Endergebnis. In den folgenden Graphiken zeigt sich deutlich, dass eine Ausdünnung der Koeffizienten schon bei sehr kleine Hyperparametern C zu schlechteren Vorhersagen führt.
Dennoch ist die Wahl dieser Methode, sofern C richtig gewählt wird, durchaus berechtigt, denn zum einen liegt eine kleine Verbesserung vor, zum anderen können zumindest die für die Entscheidung ausschlaggebenden Features isoliert werden.\newpage
\begin{figure}[ht]
\centering
	\begin{minipage}[b]{.45\linewidth}
  		\includegraphics[scale=0.4]{bilder/pareto_l1_MNIST}
  		\caption{L1 nach C mit Fixkomma}
  	\end{minipage}
  	\hspace{.05\linewidth}% Abstand zwischen Bilder
  	\begin{minipage}[b]{.45\linewidth}
  		\includegraphics[scale=0.4]{bilder/pareto_l1_float_single}
		\caption{L1 nach C mit Float}
	\end{minipage}
	\hspace{.05\linewidth}% Abstand zwischen Bilder
\end{figure}
\begin{figure}[ht]
\centering
\includegraphics[scale=.7]{bilder/pareto_l1_float}
\caption{L1 Regularisierung mit Float}
\end{figure}
Im Gegensatz dazu kann die L2 Regularisierung die Ergebnisse mit etwas größerem Hyperparameter C geringfügig verbessern, sodass bei der Wahl der Regularisierungsmethode auf Ridge Regression zurückgegriffen werden sollte. Sowohl die Vorhersagen bei der L1- als auch bei der L2 Regularisierung klassifizieren mehr Variablen mit Bezeichnung 0 korrekt als negativ, aber es werden auch mehr Variablen mit Bezeichnung 1 fälschlicherweise als negativ eingeordnet. 

\begin{figure}[ht]
\centering
	\begin{minipage}[b]{.45\linewidth}
  		\includegraphics[scale=0.4]{bilder/pareto_l2_MNIST}
  		\caption{L2 nach C mit Fixkomma}
  	\end{minipage}
  	\hspace{.05\linewidth}% Abstand zwischen Bilder
  	\begin{minipage}[b]{.45\linewidth}
  		\includegraphics[scale=0.4]{bilder/pareto_l2_float_single}
		\caption{L2 nach C mit Float}
	\end{minipage}
	\hspace{.05\linewidth}% Abstand zwischen Bilder
\end{figure}
\begin{figure}[ht]
\centering
\includegraphics[scale=.7]{bilder/pareto_l2_float}
\caption{L2 Regularisierung mit Float}
\end{figure}\newpage

\section{Festkomma- und Gleitkommazahl}
Die Wahl einer Festkommazahl im Gegensatz zu einer Gleitkommazahl liegt durch deren Eigenschaften von Beginn an nahe. Berechnungen mit Fixkommazahlen sind ressourcenschonender und schneller als Gleitkommaberechnungen, bei denen die Anzahl Bits für die Vor- und Nachkommastelle mit jeder Zahl variieren können. zudem können auf der verwendeten 32-Bit Schnittstelle von Xillybus zwei Fixkommazahlen mit der Länge von 16 oder weniger Bits gleichzeitig übertragen werden. Dies sollte die Übertragungszeit für die Daten an den FPGA halbieren. \\
Überraschenderweise sind aber die Fixkommazahlen auf dem FPGA deutlich Ressourcenabhängiger als die Gleitkommazahlen. eine Belegung des FPGA mit 16 Perceptrons erzielt für Fixkomma- und Gleitkommazahlen jeweils folgende Auslastungen:\\\\
Fixkommazahl:\\\\

\begin{tabularx}{.6\textwidth}{p{0.16\textwidth}|r|r|r}
Bauteil & Benutzt & Gesamt & Auslastung \\
\hline
LUT & 120478 & 133800 & 90.04\%\\
\hline
LUTRAM & 685 & 46200 & 1.48\%\\
\hline
FF & 757423 & 267600 & 28.18\%\\
\hline
BRAM & 37 & 365 & 10.14\%\\
\hline
DSP & 400 & 740 & 54.05\%\\
\hline
I/O & 5 & 400 & 1.25\%\\
\end{tabularx}\\\\
Gleitkommazahl:\\\\

\begin{tabularx}{.6\textwidth}{p{0.16\textwidth}|r|r|r}
Bauteil & Benutzt & Gesamt & Auslastung \\
\hline
LUT & 82816 & 133800 & 61.90\%\\
\hline
LUTRAM & 1586 & 46200 & 3.43\%\\
\hline
FF & 81956 & 267600 & 30.63\%\\
\hline
BRAM & 61 & 365 & 16.67\%\\
\hline
DSP & 400 & 740 & 54.05\%\\
\hline
I/O & 5 & 400 & 1.25\%\\
\end{tabularx}\\\\

Durch diese doch deutlich abweichenden Werte gelingt es mit Gleitkommazahlen 24 Perceptrons auf dem FPGA parallel laufen zu lassen.
Der eventuelle Zeitverlust durch die größeren Zahlen wird hierdurch ausgeglichen. \\ 
Auch auf dem Hostrechner laufen die Programme unter Gleitkommazahlen schneller und flüssiger als mit Festkommawerten. Eine mögliche Erklärung dafür ist, dass die Werte aus den Datensets in Gleitkommazahlen vorliegen und erst in Festkommazahlen umgerechnet werden müssen. Auch die Einstellungen $AP\_SAT\_SYM$ und $AP\_RND\_CONV$, obgleich sie wichtig für die Funktionalität auf dem FPGA sind, brauchen bei jeder Belegung und Berechnung Rechenzeit um die Direktiven auf die Zahl anzuwenden. Zusätzlich ist es auf dem FPGA bei größeren Batchgrößen die Berechnung der Summe der Kostenfunktionen in Gleitkommazahlen durchzuführen, wodurch eine weitere Umrechnung nötig ist. Beispielweise ist bei einer Batchgröße von 60 der maximale Wert, den ein Hilfskoeffizient annehmen kann auch 60 und damit größer als das Maximum von \textit{ap\_fixed(3, 16)}. Es bleibt also nur die Wahl zwischen dem Umrechnen in Gleitkommazahlen zum aufaddieren der Hilfskoeffizienten oder dem Dividieren der der Hilfskoeffizienten bei jeder Berechnung durch die Batchgröße. Auch die zweite Möglichkeit kann dazu führen dass der Wert nicht mehr korrekt dargestellt werden kann und zu 0 gerundet wird. 

\section{Timing und Energie}
Um die Performance der Implementierung zu erfassen wurden die verschiedenen Lese- und Schreibmethoden gemessen. Dazu wurde auf dem Hostsystem jeweils vor und nach der zu messenden Operation die Systemzeit gespeichert und subtrahiert. zusätzlich wurde die Gesamtzeit der Operationen berechnet. Um einen möglichst genauen Wert zu erhalten wurden diese Messungen für jeweils 200 oder 500 Zyklen wiederholt. Nachfolgend sind die Ergebnisse Des Zeittests:\\
\begin{figure}[ht]
\begin{tabularx}{\textwidth}{c|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X}
\multirow{2}{*}{Operation, Zeit in ms} & \multicolumn{3}{>{\hsize=3\hsize}c|}{Fixkomma mit 8 Perceptrons} & \multicolumn{3}{>{\hsize=3\hsize}c}{Float mit 16 Perceptrons} \\
\cline{2-7}
& min & $\varnothing$ & max & min & $\varnothing$ & max \\
 \hline
Lesen &426.11 & 430.472 & 442.033&740.779&767.808&770.535\\
\hline
Training &644.675 & 647.403 & 625.012&596.129&728.134&757.502\\
\hline
Test schreiben &410.963 & 414.06 & 424.923&721.724&749.679&771.331\\
\hline
 Gesamt &1075.21 & 1078.283 & 1091.621&1339.51&1496.395&1535.616\\

\end{tabularx}
\caption{200 Wiederholungen, jeweils 1.000 Trainings- und Testzyklen pro Messung}
\end{figure}
\begin{figure}[ht]
\begin{tabularx}{\textwidth}{c|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X}
\multirow{2}{*}{Operation, Zeit in s} & \multicolumn{3}{>{\hsize=3\hsize}c|}{Fixkomma mit 8 Perceptrons} & \multicolumn{3}{>{\hsize=3\hsize}c}{Float mit 16 Perceptrons} \\
\cline{2-7}
& min & $\varnothing$ & max & min & $\varnothing$ & max \\
 \hline
Lesen &3.98 & 4.16 & 4.21&7.49&7.6&7.67\\
\hline
Training &6.44 & 6.44 & 6.45&6.98&7.34&7.42\\
\hline
Test schreiben &3.97 & 4.14 & 4.19&7.48&7.58&7.65\\
\hline
 Gesamt &10.42 & 10.6 & 10.65&14.6&14.94&15.1\\

\end{tabularx}
\caption{500 Wiederholungen, jeweils 10.000 Trainings- und Testzyklen pro Messung}
\end{figure}\\
Aus den Daten lässt sich schließen dass die Implementierung mit der doppelten Anzahl an Perceptrons und Bits im Zahlenformat keine so großen Auswirkungen auf die gemessenen Zeiten hat. Trotz Vervierfachung der zu schreibenden und lesenden Bits erhöht sich die Zeit im ersten Test für das Lesen nur um 78,3\%, für das Training um 12,5\%, für das Testen um 81\% und für die Gesamtzeit um 38,8\%. Die Gesamtzeit pro Perceptron würde für die Festkommazahl 134.75 ms und für die Gleitkommazahl 93.525 ms betragen. Diese Werte gelten für das Trainieren und Testen von jeweils 1000 Variablen mit 784 Features. Interessanterweise ist bei der Festkommazahl das Testen am schnellsten, bei der Gleitkommazahl jedoch das Training. Dies lässt sich auf die zusätzlichen Umrechnungen der Werte auf dem FPGA bei der Festkommazahl zurückführen.\\
Lässt man die Perceptrons auf dem Hostrechner selbst trainieren, so erhält man folgende Werte:\\
\begin{figure}[ht]
\centering
\begin{tabularx}{.6\textwidth}{c|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X}
\multirow{2}{*}{Operation, Zeit in s} & \multicolumn{3}{>{\hsize=3\hsize}c}{1.000 mal Training und Tests} \\
\cline{2-4}
& min & $\varnothing$ & max\\
\hline
Training &43.34 & 43.43 & 43.76\\
\hline
Test schreiben &8.75 & 8.77 & 8.87\\
\hline
 Gesamt &52.09 & 52.21 & 52.56\\

\end{tabularx}
\caption{500 Wiederholungen für Perceptrons auf dem Hostsystem, 8 Perceptrons}
\end{figure}\\
Die Zeiten des Hosts zeigen, wie gut die Implementierungen auf dem FPGA gegenüber einer direkten Programmierung abschneiden. Ganze 48.6 mal mehr Zeit braucht der Hostrechner gegenüber der Fixpunkt Implementierung und 34.8 mal mehr als die der Gleitkommazahl. An dieser Stelle ist zu erwähnen, dass der Prozess auf dem Hostrechner weder parallelisiert noch optimiert wurde und somit das Multithreading moderner Prozessoren nicht ausgenutzt wurde. Es wurde lediglich naiv der Code für die Perceptrons in Reihe geschaltet und entsprechend häufig der Anzahl der Perceptrons auf dem FPGA ausgeführt.\\\\
Auch der Energieverbrauch der Implementierungen ist überschaubar. So hat die Implementierung mit 8 Perceptrons einen Verbrauch von 1.795 Watt und die Implementierung mit 16 Perceptrons und Gleitkommazahl 2.338 Watt.
Zum Vergleich: Der Hostrechner verbraucht als Verlustleistung schon 130 Watt \cite{INTEL}. Eine GPU würde unter Last bis zu 538 Watt verbrauchen \cite{GPU}.

\section{Probleme}
Bei der Implementierung der Hostanwendung gab es einige Hürden zu überwinden. Vor allem das Timing und die Abstimmung mit dem FPGA sind essentiell für die Reibungslose Kommunikation beider Systeme. Bei Implementierungen von Fixkommazahlen mit mehr als 8 Perceptrons konnte der Hostprozess die Daten einiger Perceptrons nicht mehr auslesen. Erst das Umstellen auf einen linearen Programmverlauf führte zu einer Verbesserung der Kommunikation, zu Ungunsten der Laufzeitdauer. Der Grund dieser Störungen konnte nicht ermittelt werden, es steht jedoch die Latenz der Verteiler- und Sammlerklassen im Verdacht. Eine Aufteilung der Klassen und die damit verbundene Verminderung der Latenzzeiten brachte jedoch nicht den gewünschten Erfolg, sodass auf eine Gleitkommazahl-Implementierung ausgewichen werden musste.
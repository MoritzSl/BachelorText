% einleitung.tex
\chapter{Einleitung}
\section{Motivation und Hintergrund}
Maschinelles Lernen und Vorhersagen werden immer mehr in unser Leben integriert. Hierbei entsteht zum einen der Anspruch an variable, nicht statische Systeme, zum anderen die Notwendigkeit kompakter und energieeffizienter Lösungen.\\
Aufgrund der immer weiter wachsenden Datenmengen stoßen herkömmliche Central Processing Units (CPUs) mittlerweile an Ihre Grenzen, denn durch materialbedingte Limitierung kann ihre Rechenkapazität so gut wie nicht mehr erhöht werden. Daher geht man dazu über, Mehrkernprozessoren zu entwickeln, die ihre Geschwindigkeit über parallele Threads erreichen. Diese haben jedoch einen vergleichsweise hohen Energieverbrauch.\\
Field Programmable Gate Arrays (FPGAs) bieten in diesem Zusammenhang einen guten Kompromiss zwischen Flexibilität in der Programmierbarkeit und Energieeffizienz. Der Vorteil der FPGAs zeigt sich in der deutlich höheren Parallelität gegenüber CPUs, sodass trotz der geringeren Taktfrequenz eine große Menge an Daten schnell verarbeitet werden kann.\\
Die logistische Regression ist für die Optimierung auf FPGAs in dem Sinne gut geeignet, da sie eine einfache Art von neuronalem Netz darstellt und somit gut in der FPGA-Logik darstellbar ist. Sie weist zum Beispiel durch Datenparallelität bzw. Parallelisierung von Batches, Feature- oder Hyperparameter-Berechnung eine hohe Parallelisierbarkeit auf.\\\\
Moderne FPGAs können über die PCIe-Schnittstelle als Co-Prozessor in ein System eingebunden werden, sodass deren Parallelität und Energieeffizienz ausgenutzt werden können. Dank des hohen Durchsatzes der Schnittstelle muss hierbei nicht auf eine komplexe variable Vorbereitung der Daten durch die CPU im laufenden Betrieb verzichtet werden.\\
Die Motivation zur Nutzung von FPGAs besteht darin, dass sie Energieeffizienz und Parallelität miteinander kombinieren. Sie bieten einen guten Kompromiss zur Nutzung von Graphics Processing Units (GPUs), denn diese weisen zwar eine noch höhere Parallelisierungseigenschaft auf, benötigen aber auch deutlich mehr Energie, bis zu 20x mehr allein im Idle-Zustand \cite{GPU}.

\section{Aufbau der Arbeit}
In Kapitel 2 werden zunächst der Aufbau und die Funktionsweise von FPGAs erläutert. Es wird auf die technischen Besonderheiten und die Funktion der Einzelnen Hardwarebausteine eingegangen. Außerdem wird der Konfigurationsablauf zur Programmierung des FPGAs erklärt und seine Eigenschaften mit denen von anderen Hardwarekomponenten verglichen.\\\\
Im 3. Kapitel erörtern wir die Zusammensetzung der Logistischen Regression. Ihre Funktion als Lernfunktion wird detailliert beschrieben und mit Hilfe des Gradientenabstiegsverfahrens wird eine Updatefunktion für Koeffizienten hergeleitet. Es folgt eine Vorstellung verschiedener Regularisierungsmethoden sowie deren Einbindung in in die Updatefunktion.\\\\
in Kapitel 4 werden die Implementierten Programme dargestellt und der Code erörtert. Man geht auf die Probleme der Entwicklung für den FPGA-Code und den Hostanwedungs-Code ein, sowie dessen Grenzen in der Anwendung.\\
Kapitel 5 fast die Ergebnisse von Experimenten mit dem FPGA zusammen. Es werden beispielhaft Daten ausgewertet und Trainingsergebnisse vorgestellt.Auch eine Analyse der Geschwindigkeit im Vergleich zu einer CPU werden behandelt. \\Im 6. Kapitel wird das Fazit aus den behandelten Themen und Ergebnissen dieser Arbeit gezogen. Es werden Empfehlungen für weitere, tiefer gehende Implementierungen und Experimente gegeben, die zum Teil aus Zeit- und Aufwandstechnischer Sicht in der Arbeit nicht behandelt werden.
\section{Verwandte Arbeiten}
Es gibt bereits einige Arbeiten zu dem Thema logistische Regression auf FPGAs die sich mit der Energie- und Geschwindigkeitsoptimierung auseinandersetzen.
Wienbrandt et al. benutzen ein FPGA mit logistischer Regression in \cite{WIENB} und zeigen, dass ein hybrides System aus GPU und FPGA einen Speedup von über 1500 gegenüber einem PLINK hat. Allerdings benutzten sie zum Einen eine GPU mit einem Energieverbrauch von 300 Watt \cite{P100}, was im Gegensatz zu einem einzelnen Artix 7 FPGA mit einem Verbrauch von ca. 5 Watt \cite{WAT} sehr hoch ist, und zum anderen werden in dem Artikel keine Werte eines FPGAs als einzelnes System gemessen.
Es gibt bereits eine Implementierung von InAccel von logistischer Regression auf FPGAs \cite{ACC} die sich jedoch vor allem auf die Nutzung in vernetzten Systemen und Kubernetes bezieht. Zum Beispiel werden in der Implementierung alle benötigten Ressourcen für die maximalen Eingabegrößen (64 Klassen und 2047 Features) auf jedem FPGA reserviert,
was vor allem für Trainingsdaten mit deutlich weniger Features eine unnötige Speicherausnutzung bedeutet. Es wird mit float8 bzw float16 gearbeitet, sodass eine Implementierung mit Fixkommazahlen eine noch etwas bessere Performance erzielen könnte. Die Implementierung nutzt zudem keine PCIe Schnittstelle und programmiert die FPGAs während des Hostprozess mit einem Bitstream jedes mal erneut.
\chapter{Fazit und Empfehlungen}
\section{Fazit}
In dieser Arbeit wurden Optimierungen für die logistische Regression auf FPGAs vorgenommen und erläutert. 
Der allgemeine Aufbau und die Struktur von FPGAs wurde detailliert dargestellt. Die Methode der logistischen Regression wurde erklärt und Regressionsmethoden für den Lernprozess vorgestellt. Die Vorzüge der logistischen Regression für FPGAs sind, dass durch das Gradientenabstiegsverfahren nur Updates der Koeffizienten nötig sind und dass die Berechnungen dieser Koeffizientenupdates durch einfache oder bereits auf dem FPGA hinterlegte Funktionen durchgeführt werden können. Weiterhin wurde die Implementierung eines Modells für den FPGA bereitgestellt und der dazugehörige Hostprozess programmiert. In den Experimenten gab es einen Einblick in die Möglichkeiten und Probleme der Modellumsetzung.\\\\
Die Arbeit zeigt, dass es durchaus möglich ist logistische Regression auf FPGAs zu implementieren ohne einen großen Kompromiss bezüglich der Trainingsdauer eingehen zu müssen. Im Gegensatz zu einer naiven Durchführung auf dem Hostrechner ist der FPGA sogar bedeutend schneller und effizienter.\\
Für Problemstellungen, die eine Vielzahl von verschiedenen trainierten Modellen benötigen ist der FPGA besonders geeignet. Ein Beispiel hierzu ist das Finden eines optimalen Hyperparameters C für die Gewichtung von Regularisierungsmethoden. Dieser lässt sich zwar mathematisch begrenzen \cite{NG}, jedoch nicht berechnen und wird als schwierig zu wählen beschrieben \cite{TRAN}. An dieser Stelle ist die Parallelität des FPGAs von Vorteil, denn es können in geringer Zeit viele Modelle, nur voneinander abweichend durch die Wahl des Hyperparameters, trainiert werden und die Ergebnisse dem Nutzer als Pareto-Front vorgestellt werden. Eine beispielhafte Bearbeitung des MNIST Datensatzes \cite{MNIST} ist in Kapitel 5 durchgeführt worden.\\\\
Durch die Wahl der High-Performance Schnittstelle über PCIe von \cite{DILL} als Grundlage für die Arbeit ist die Notwendigkeit von Datenspeichern auf dem FPGA nicht gegeben. Dies ermöglicht die volle Nutzung der Hardwarekomponenten durch die Perceptrons selbst.
\\Im Vergleich zu gängigen CPUs und auch GPUs ist die für die Durchführung der Programme erforderliche Energie besonders niedrig. Man kann demnach eine Implementierung von logistischer Regression auf FPGAs durchaus als Energieeffizient bezeichnen. Grade in der heutigen Zeit, wo Ressourcen schonende Verfahren an Popularität gewinnen und aufgrund der Weltklima-Lage durchaus auch von Nöten sind, erhält diese Eigenschaft einen besonderen Stellenwert. Die dazu erforderlichen technischen Eigenschaften sind auf FPGA durchaus vorhanden, und es konnte gezeigt werden dass es auch den theoretischen Anforderung an Trainingsmodellen gerecht wird.

\section{Empfehlungen}
Einige in dieser Arbeit aufgrund von technischen oder zeitlichen Anforderungen nicht behandelte Realisierungsmöglichkeiten werden hier aufgeführt. Dies soll einen Anstoß für weitere Arbeiten mit und Verbesserungen an dem präsentierten Konzept geben. Das FPGA, oder genauer das Evaluation-Kit des in dieser Arbeit benutzen FPGAs enthält einen 3 GB großen DDR3 RAM. Anstatt mit Der PCIe Schnittstelle als Hauptmedium zur Datenvermittlung kann auch der Trainingsdatensatz in diesen Speicher geladen werden. Es wäre dadurch,nach der Übertragung des Datensatzes, nur eine minimale Kommunikation mit dem FPGA erforderlich um die selben Aktionen mit ihm durchzuführen, die auch in dieser Arbeit behandelt wurden. Die Verknüpfung des FPGAs mit der DDR3 Schnittstelle ist jedoch nicht trivial und beinhaltet viele mögliche Fehlerquellen, kann jedoch zu noch besseren Ergebnissen im Hinblick auf die Trainingszeit liefern.\\\\
In \cite{FS} wird eine Möglichkeit der Feature-Selection über Daten oder Feature Streams beschrieben. Da die Kommunikation Des FPGA mit dem Hostrechner über Streams erfolgt, wäre dies eine gute Grundlage für eine Implementierung dieser Methode. Für komplizierte Algorithmen ist jedoch eine Approximation notwendig, denn ähnlich wie bei GPUs zeichnet sich die Bearbeitung von Daten auf dem FPGA nicht durch Komplexität, sondern durch Parallelität aus.\\\\
Das auch das Training eines einzelnen Modells durch ein FPGA beschleunigt werden kann lässt sich aus der Parallelisierung der SGD in \cite{ZINKE} erkennen. Anstatt hier die einzelnen Schleifen auf verschiedene Maschinen zu verteilen ist es möglich, diese auf dem FPGA parallel zu implementieren und miteinander Kommunizieren zu lassen. Der beschriebene I/O-Overhead könnte dadurch umgangen werden.\\\\
Viele Datensätze liegen nicht, wie in dieser Arbeit vorausgesetzt in dichotomer Form vor. Demnach liegt die Implementierung einer multinomialen logistischen Regression nahe. Diese kann mehrere Ausprägungen dadurch vorhersagen, dass für jede Ausprägung eine logistische Regression mit dieser als "`trifft zu"' und aller anderen als "'trifft nicht zu"' trainiert wird. Die Ausgabe wird zugunsten der am eindeutigsten getroffenen Entscheidung gewählt. Da hier mehrere Modelle benötigt werden, die alle auf den selben Daten (außer den Labeln) trainiert und getestet werden ist das FPGA prädestiniert für diese Aufgabe. Die finale Entscheidung kann in der Kollektorklasse auf dem FPGA noch vor der Ausgabe  an den Nutzer erfolgen.